<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chenat9.github.io</id>
    <title>Fly</title>
    <updated>2021-02-05T08:23:46.082Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chenat9.github.io"/>
    <link rel="self" href="https://chenat9.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://chenat9.github.io/images/avatar.png</logo>
    <icon>https://chenat9.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Fly</rights>
    <entry>
        <title type="html"><![CDATA[Golang Pipeline]]></title>
        <id>https://chenat9.github.io/post/golang-pipeline/</id>
        <link href="https://chenat9.github.io/post/golang-pipeline/">
        </link>
        <updated>2021-02-05T08:16:23.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>本文介绍 Golang 中的一种并发编程模式，Pipeline 流水线模式。</p>
<h4 id="什么是流水线模式">什么是流水线模式？</h4>
<p>流水线顾名思义，即一系列处理单元组成的一套处理逻辑。</p>
<h4 id="为什么需要流水线模式">为什么需要流水线模式？</h4>
<p>编程当然可以写成串行的方式，但是这样带来的缺点是，如果某一个阶段耗时比较久，将会导致CPU空闲，这一点就不必多说了，因此引入了并发编程。<br>
流水线模型是并发编程模式的一种，并发编程可以使得计算机可以同时处理多个数据。而在 Golang 中，由于 Goroutine 的存在使得并发编程异常简单，Goroutine 之间需要数据传递，由于 channel 的存在也简化了许多。</p>
<h4 id="怎么组装一条流水线使用-channel-连接">怎么组装一条流水线？使用 Channel 连接</h4>
<p>在流水线中，每个处理单元称为一个 Stage，每个 Stage 都需要接受上游传来的数据，经过当前 Stage 处理后，再对下游传递。Channel 可以很好的承担传递数据的角色，也就是每个 Stage 都必须有两个 channel，一个负责接受数据的 channel 和一个负责对外发送数据的 channel。</p>
<p>Golang 提供的 channel 通信机制，可以帮助我们便捷的组装各个 stage，下面将通过实例说明。</p>
<h5 id="一个简单的例子求平方数">一个简单的例子：求平方数</h5>
<p>我们在这个例子中，将会输入 int 类型的参数，输出各个数的平方值，尽管这个逻辑可以用十分简单的代码实现，但我们还是将他分成3个 stage 来实现，以验证 golang pipeline 编程模型所带来的好处。</p>
<p>Stage1 ：</p>
<p>首先要产生数字，将这个 stage 取一个直观的名字 gen，输入参数是 int 列表，返回值是一个 channel。</p>
<pre><code class="language-go">func gen(nums …int) &lt;-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out &lt;- n
        }
        close(out)
    }()
    return out
}
</code></pre>
<p>Satge2 ：<br>
按照我们对 Pipeline 的定义，输入是一个 channel，输出还是一个 channel，处理逻辑即对收到的每个数进行平方</p>
<pre><code class="language-go">func sq(in &lt;-chan int) &lt;-chan int {
	out := make(chan int)
	go func() {
		for n := range in {
			out &lt;- n * n
		}
		close(out)
	}()
	return out
}
</code></pre>
<p>Stage3：<br>
最后一个 stage，也是 main 函数，他将会输出这些值。</p>
<pre><code class="language-go">func main() {
	in := gen(2, 3)
	c1 := sq(in)
	for n := range c1 {
    fmt.Println(n)
	}	
}
</code></pre>
<h4 id="扇入扇出-fan-out-fan-in多个-routine-同时处理">扇入扇出 Fan-Out、Fan-In：多个 Routine 同时处理</h4>
<p>我不认为扇出扇出是一个好的翻译，这两个单词单独去看并不能让我很直观的了解具体代表的逻辑。Fan-Out 和 Fan-In 是来自电子电路领域的一个概念，如果一个模块输出连接到了多个模块称为Fan-Out.<br>
移植这个概念到 软件的领域，自然指的是一个输出 Channel 连接多个 Staging。利用这个方式，我们可以将工作分发给更多的处理任务，提高并发度。当然，接收端也可以从多个 channel 接受数据。</p>
<pre><code class="language-go">func main() {
   in := gen(2, 3, 3,3)
   // Distribute the sq work across two goroutines that both read from in.
   c1 := sq(in)
   c2 := sq(in)

   out := merge( c1, c2)
   fmt.Println(&lt;-out)
}
</code></pre>
<p>分发给两个 sq，这是典型的 Fan-Out 操作，还引入了一个 merge 函数，这个函数是将两个 channel 输入，输出给一个 output channel，显然这是 Fan-In 操作。<br>
但是 merge 函数有一个重要的点需要注意，输出的 output channel 必须在所有数据发送完成后调用 close方法去关闭。如果过早的关闭，还有未发送的数据，如果发送到已经关闭的 channel上，会引起 panic。如果过晚的关闭或者不关闭，会造成资源泄露或者 main 函数一直在等待数据发送结束。<br>
这是一个很简单的同步模型，Golang 中提供了 WaitGroup 方式来实现这种逻辑。</p>
<pre><code class="language-go">func merge(cs ...&lt;-chan int) &lt;-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c is closed, then calls wg.Done.
    output := func(c &lt;-chan int) {
        for n := range c {
            out &lt;- n
        }
        wg.Done()
    }
    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }

    // Start a goroutine to close out once all the output goroutines are
    // done.  This must start after the wg.Add call.
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
</code></pre>
<h5 id="提前结束">提前结束</h5>
<p>首先明确两个要点：<br>
output channel必须在数据全部发送完之前，一直保持 open<br>
只要 channel 还在 open 状态，就必须从里面接受数据<br>
接下来我们将处理两种特殊情况。<br>
之所以说是特殊情况，是因为在正常的逻辑中，我们会等到上游所有的数据发送完，下游所有的数据接受完以后关闭channel ，从而使得 goroutine 能够顺利被回收。但这种情况并不一定是我们每次都需要的，比如我们只需要结果的一个子集，又或者上游的 Stage 产生了异常，这种情况我们都没有必要接受完全部的数据再处理，这种情况我们称为提前结束。<br>
提前结束不是仅仅不再接受数据即可，但是这里还涉及到合理的关闭各个 channel，如果下游已经不想接受数据，上游的发送还没完成的话，上游将会永远阻塞，这会导致 goroutine 泄露，如果在常驻进程中，这可能是一笔极大的损耗。<br>
因此必须有一个机制来通知上游 stage：我们不再接受数据。首先想到的是增加一个 channel，用来在下游和上游中做消息通知。</p>
<pre><code class="language-go">func main() {
    in := gen(2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(in)
    c2 := sq(in)

    // Consume the first value from output.
    done := make(chan struct{}, 2)
    out := merge(done, c1, c2)
    fmt.Println(&lt;-out) // 4 or 9 

    // Tell the remaining senders we're leaving.
    done &lt;- struct{}{}
    done &lt;- struct{}{}
}
</code></pre>
<p>我们模拟了下游出现异常的情况，只在 out 中接受了一个数据就不再接受了，此时如果不关闭上游 channel，将会造成资源泄露。</p>
<p>我们在 main 函数中增加了一个 done channel，并且把该 channel 放入到 merge 方法中，用来接受信号。</p>
<p>这里连续对两个 done 发送消息的原因是因为，在下面的 merge 函数中，select 在 done 接受到消息后，会顺序执行下面的所有指令，即 wg.Done()，而在示例代码中有两个 channel 被放入到output 中处理，因此两个 channel 都要被关闭。</p>
<pre><code class="language-go">func merge(done &lt;-chan struct{}, cs ...&lt;-chan int) &lt;-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c is closed or it receives a value
    // from done, then output calls wg.Done.
    output := func(c &lt;-chan int) {
        for n := range c {
            select {
            case out &lt;- n:
            case &lt;-done:
            }
        }
        wg.Done()
    }
    // ... the rest is unchanged ...
</code></pre>
<p>这种方式有明显的缺点，你必须知道上游有多少个 channel Fan-In，才能在下游发送多少个 done 消息去关闭每一个 channel，下面我们改进一下。</p>
<h5 id="自动化一点利用-close-channel-通知">自动化一点：利用 Close Channel 通知</h5>
<pre><code class="language-go">func main() {
    // Set up a done channel that's shared by the whole pipeline,
    // and close that channel when this pipeline exits, as a signal
    // for all the goroutines we started to exit.
    done := make(chan struct{})
    defer close(done)

    in := gen(done, 2, 3)

    // Distribute the sq work across two goroutines that both read from in.
    c1 := sq(done, in)
    c2 := sq(done, in)

    // Consume the first value from output.
    out := merge(done, c1, c2)
    fmt.Println(&lt;-out) // 4 or 9

    // done will be closed by the deferred call.
}
</code></pre>
<p>在 merge 函数中增加对 done channel 的处理，因为我们不关心 done channel 的接收到的值是什么，当done channel 被 close 时，所有 stage 都可以在 done channel 中接受到 0 值。</p>
<p>当 done 中接受到值时，直接return，return 时defer 函数将会自动执行 wg.Done()。</p>
<pre><code class="language-go">func merge(done &lt;-chan struct{}, cs ...&lt;-chan int) &lt;-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    // Start an output goroutine for each input channel in cs.  output
    // copies values from c to out until c or done is closed, then calls
    // wg.Done.
    output := func(c &lt;-chan int) {
        defer wg.Done()
        for n := range c {
            select {
            case out &lt;- n:
            case &lt;-done:
                return
            }
        }
    }
    // ... the rest is unchanged ...
</code></pre>
<p>这里的 return 和 defer 是相互搭配的，也可以不使用 return，但必须手动增加 defer 对应的逻辑。</p>
<p>对应的，上游 stage 也应该执行相同的 close 操作。</p>
<pre><code class="language-go">func sq(done &lt;-chan struct{}, in &lt;-chan int) &lt;-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for n := range in {
            select {
            case out &lt;- n * n:
            case &lt;-done:
                return
            }
        }
    }()
    return out
}
</code></pre>
<p>两个 Guideline：<br>
stages close their outbound channels when all the send operations are done.<br>
要么所有数据发送完，主动关闭。<br>
stages keep receiving values from inbound channels until those channels are closed or the senders are unblocked.<br>
要么持续从上游接受数据，直到上游关闭或者发动端全部发完。</p>
<p>引用连接：</p>
<p><a href="https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-select/#%E9%9A%8F%E6%9C%BA%E6%89%A7%E8%A1%8C">Golang Select机制</a></p>
<p><a href="https://blog.csdn.net/chizong2116/article/details/100732815?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control">Goroutine 泄露的几种情况</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bochs 安装]]></title>
        <id>https://chenat9.github.io/post/bochs-an-zhuang/</id>
        <link href="https://chenat9.github.io/post/bochs-an-zhuang/">
        </link>
        <updated>2021-02-01T13:13:49.000Z</updated>
        <content type="html"><![CDATA[<h3 id="环境">环境</h3>
<p>OSX Catalina</p>
<h3 id="安装指令">安装指令</h3>
<p>最开始尝试下载 bochs 的源码编译安装，但是提示找不到 &lt;linux/type.h&gt; 头文件。后来查找资料，发现使用 brew 即可安装 bochs</p>
<pre><code>brew install bochs
</code></pre>
<p>安装完成后，可以执行 bochs，打印出出错信息，说明 bochs 已经安装成功。<br>
<img src="https://chenat9.github.io/post-images/1612271089265.png" alt="" loading="lazy"></p>
<h3 id="配置bochs">配置bochs</h3>
<p>配置文件：bochsrc.disk</p>
<pre><code>megs: 32

romimage: file=$PATH/bochs-2.6.10/bios/BIOS-bochs-latest
vgaromimage: file=$PATH/bochs-2.6.10/bios/VGABIOS-lgpl-latest

boot: disk

log: bochs.out

mouse: enabled=0

keyboard: keymap=$PATH/bochs-2.6.10/gui/keymaps/sdl2-pc-us.map

ata0: enabled=1, ioaddr1=0x1f0, ioaddr2=0x3f0, irq=14

#gdbstub: enabled=1, port=1234, text_base=0, data_base=0, bss_base=0

</code></pre>
<p>上述参数具体解释在后面已经说明，需要注意的是一些配置文件需要指定路径，使用 brew 方式安装的 bochs 没有这些文件（或者我没有找到...)，因此可以下载 bochs 的源码，按上述中的路径找到后配置在文件中。</p>
<h3 id="运行-bochs">运行 bochs</h3>
<p>当配置完成后，可以运行 bochs 命令来启动</p>
<pre><code>bochs -f bochsrc.disk
</code></pre>
<p>运行后，按 C 键，系统将会跳出 bochs 的 UI 窗口，如下图所示，可以看到 No bootable device.的错误，这是由于没有指定启动盘。<br>
<img src="https://chenat9.github.io/post-images/1612271130070.png" alt="" loading="lazy"></p>
<h3 id="指定启动盘">指定启动盘</h3>
<p>要指定启动盘，首先要有一个启动盘。安装 bochs 的时候，会自带一个制作 image 的工具:bximage<br>
<img src="https://chenat9.github.io/post-images/1612271165343.png" alt="" loading="lazy"><br>
运行bximage 命令后，选择创建默认 IMG，输入一些配置以及输出路径即可（可以都按默认配置），生成 IMG 文件成功后，bximage 会贴心的告诉你</p>
<pre><code>The following line should appear in your bochsrc:
  ata0-master: type=disk, path=&quot;c.img&quot;, mode=flat
</code></pre>
<p>将这一行添加到配置文件中，再次启动 bochs，按 C 运行。可以看到依然显示 No bootable device，但错误原因已经变了。<br>
<img src="https://chenat9.github.io/post-images/1612271118120.png" alt="" loading="lazy"><br>
这次是因为img 中没有可以启动的代码，接下来就去编写 MBR 引导程序吧。<br>
<img src="https://chenat9.github.io/post-images/1612271191661.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Async/Await]]></title>
        <id>https://chenat9.github.io/post/asyncawait/</id>
        <link href="https://chenat9.github.io/post/asyncawait/">
        </link>
        <updated>2020-11-23T16:03:41.000Z</updated>
        <content type="html"><![CDATA[<p>在这篇文章，我们将探索Rust 中的多任务机制和异步/等待特性。我们详细的剖析异步/等待机制如何工作，包括 Future 的设计，状态机转换和 pinning。我们增加了基础的支持在内核中。通过创建异步键盘任务和基本的执行器。</p>
<h3 id="多任务">多任务</h3>
<p><code>多任务</code> 是大多数操作系统的基本特性之一，这是一种允许多任务并行执行的能力。 举例来说，你可能打开了一个程序来看这片文章，比如文字编辑器或者 Terminal 窗口，甚至可能有打开了一个单独的浏览器窗口。各种各样任务在后台运行，这样你才能够管理桌面窗口，检查更新或者索引文件。<br>
任务看起来是并行的，但实际上CPU在同一时刻只允许一个任务在执行。为了让用户产生程序在同时运行的错觉，操作系统必须在不同的后台程序之间快速的切换。<br>
但是，单核 CPU 同时只能运行一个任务，但多核 CPU 可以真正同时运行多个任务。<br>
多任务处理系统有两种常见形式：协作式多任务处理系统需要任务主动放弃 CPU 的控制权，以便其他任务可以进行。抢占式多任务使用操作系统提供的能力去切换，操作系统可以任意的强制停止他们。接下来，我们将详细介绍两者的不通。</p>
<h4 id="抢占式多任务">抢占式多任务</h4>
<p>抢占式多任务的核心观念是由操作系统来控制何时切换任务。正因如此，它充分利用了在每个中断发生时，操作系统都会重新获得 CPU 控制权这个特点。这也使得无论何时，当系统中有新的输入可用时得以切换任务。比如，鼠标移动或者网络包到达。<br>
不仅如此，操作系统也可以在配置硬件系统，令其在达到某个时间后主动发送中断，</p>
<p>在第一行，CPU 正在执行 A程序中的 A1任务。其他任务均被暂停。在第二行中，硬件中断到达 CPU。CPU 立刻停止A1任务，然后跳到在 IDT 中定义的了中断处理器。通过指定的中断处理器，操作系统现在重新获得 CPU 控制权，然后然后操作系统允许CPU切换到 B1 任务继续运行。</p>
<h5 id="状态保存">状态保存</h5>
<p>程序可能被任意终止，无论程序是否进行计算。因此稍后继续恢复运行，操作系统必须保存程序运行的全部状态，包括程序调用栈，和 CPU 寄存器的值。这个过程就称为上下文切换。<br>
由于调用栈可能特别庞大， 操作系统每个任务单独设置了自己的调用栈，避免每次任务切换时，需要保存所有任务的调用栈。通过使用单独的调用栈，在任务切换时，只有寄存器内容需要被保存。这个方式最小化了性能损耗，这是上下文切换能够达到100 times/s 的关键。</p>
<h5 id="讨论">讨论</h5>
<p>抢占式多任务的最主要的优势在于操作系统可以完全控制任务的运行时间。内核可以保证每一个任务可以获得公平的 CPU 时间，不需要信任其他任务。这对于运行一些多用户或者第三方系统式很有用，因为第三方应用程序可能会占据 CPU 时间不释放。</p>
<p>劣势在于抢占式任务需要每个都有自己的栈。与共享栈对比，导致了更高的内存使用率，而且经常达到任务数的上限。另外一个劣势是，操作系统总是需要保存完整的 CPU 寄存器状态，即便在任务发生切换时，程序只使用了一部分寄存器。</p>
<h4 id="协作式多任务">协作式多任务</h4>
<p>不同于抢占式任务可以在任意时间点强制停止任务，协作式多任务系统允许每个任务主动放弃 CPU 的控制权。任务可以自由选择可以暂停的时间点，比如当程序需要等待 IO 操作时。</p>
<p>协作式多任务的实现通常是在语言层面，比如 Rust 的async/await。这个功能使得无论是程序员或者编译器在程序中插入 yield，都可以放弃 CPU控制权，允许其他程序运行。比如，在每一轮复杂的循环过后进行 yield。</p>
<p>将多任务系统和异步操作绑定在一起，是非常自然的。不同于等待一个操作完成和阻止其他任务同时运行，异步操作会返回一个还没准备好状态。比如，阻塞任务执行一个 yield 操作让其他任务运行。</p>
<h5 id="状态保存-2">状态保存</h5>
<p>由于任务可以自定义他们的暂停点，也就不再需要操作系统去保存他们的运行状态。取而代之的是他们只需要精确的存储他们真正需要的状态，这样就会有更好的性能。比如，一个任务再复杂的计算后，也许只需要保存结果。</p>
<p>对于实现而言，协作式任务有语言层面的支持，协作式任务能够备份他们需要的部分调用栈。通过只保存相关部分，所有的任务可以共享一个调用栈，这样可以消耗更小的内存。</p>
<h5 id="讨论-2">讨论</h5>
<p>协作式任务的缺点是，一个程序可以不释放CPU，一个恶意程序会阻止其他程序运行，甚至拖慢整个系统。协作式任务必须被所有的任务互相信任。比如，操作系统内核就不能基于用户级程序实现。</p>
<p>然而，强力的性能和内存友好是协作式程序一大有点，尤其是和异步操作绑定时。因此一个操作系统内核搭配支持异步的硬件，协作式任务是一个好的方式去实现并发功能。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTP 流式传输]]></title>
        <id>https://chenat9.github.io/post/http-liu-shi-chuan-shu/</id>
        <link href="https://chenat9.github.io/post/http-liu-shi-chuan-shu/">
        </link>
        <updated>2020-11-23T03:04:09.000Z</updated>
        <content type="html"><![CDATA[<h4 id="问题场景">问题场景</h4>
<p>日常工作跟分布式存储相关，遇到这样一个业务场景：</p>
<blockquote>
<p>将大文件通过 HTTP 协议传输到服务端。无法一次加载到内存中，组装到 Request 的 body 中。</p>
</blockquote>
<p>针对这样的问题，应该怎么解决呢？最简单的思路就是分而治之，将大文件分割成小文件上传，但是同一个大文件显然不能通过多次 HTTP 请求发送(这样会被认为是多个文件)。<br>
HTTP 流式传输为我们提供了相应的解决方案。</p>
<p>先来看几个知识点：</p>
<h4 id="keepalive模式">KeepAlive模式</h4>
<p>大学的知识学完，对 HTTP 的认知只停留在了少数几个关键词：HTTP 是无状态无连接的。</p>
<p>无连接的意思是指HTTP协议采用“请求-应答”模式，当使用普通模式，即非KeepAlive模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接；</p>
<p>后来 Web 的世界越来越精彩，一个网页中可能嵌套了多种资源，比如图片、视频，为了解决频繁建立 TCP 连接带来的性能损耗，出现了 Keep-Alive 模式。当使用Keep-Alive模式（又称持久连接、连接重用）时，Keep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。</p>
<p>HTTP 本身是无状态的，那么Keep-Alive 的功能必然是依赖 TCP 来实现的。TCP 的实现中包含一个 Keep-Alive 定时器，当一条数据流中没有数据通过时，服务端每隔一段时间会向客户端发送一个不带数据的 ACK 请求，如果收到 Client回复，表明连接依然存在。如果没有收到回复，Server会多次 ACK，达到一定次数以后还没有收到回复，默认此连接关闭。</p>
<figure data-type="image" tabindex="1"><img src="https://chenat9.github.io/post-images/1606100739103.png" alt="" loading="lazy"></figure>
<p>另外需要说明的是，Keep-Alive 模式在HTTP 1.0中默认是关闭的，需要在HTTP头加入&quot;Connection: Keep-Alive&quot;，才能启用Keep-Alive；HTTP 1.1中默认启用Keep-Alive，如果加入&quot;Connection: close &quot;，才关闭。但是若想完成一次 Keep-Alive 的连接，仍旧需要 Client 和 Server 端共同支持，如果某一端处理完请求直接关闭了 Socket，神仙也保证不了连接。</p>
<p>大文件的上传既然不可能一次性放到 RequestBody 中传输，那么就避免不了多次传输。Keep-Alive 模式解决了不必重复频繁建立连接的问题，第二个问题随之而来，怎么判断数据流的结束？</p>
<p>在请求-响应模式下，每一次 HTTP 请求发送完成，Client 都会主动关闭连接，Server 端在读取完所有的 Body 数据后，就认为此次请求已经完毕，开始在服务端进行处理。但是在 Keep-Alive模式下，这个问题显然就没有这么简单了。举个例子，比如一条 Keep-Alive 的HTTP 连接 ，通过底层的 TCP 通道连续发送了两张图片，对于服务器来说，如何判断这是两张图片？而不是把他们当做同一个文件的数据进行处理呢？再比如，普通模式下，客户端请求服务器的数据，服务端发送完响应就会关闭连接，客户端读取时会读到 EOF(-1)，这个时候客户端就会关闭自身的连接。但在 Keep-Alive 模式下，服务器不会主动关闭连接，Client 自然也就读不到 EOF，客户端该如何判断数据流的结束呢。</p>
<h4 id="判断数据流结束的方法">判断数据流结束的方法</h4>
<p>HTTP 为我们提供了两种方式</p>
<ol>
<li>
<p>Content-Length</p>
<p>这是一个很直观的方式，在要传输的数据前增加一个信息，来告知对端将要传输多少数据，这样在另一侧读取到这个长度的数据后，可以认为接受已经完成。</p>
<p>如果无法提前预知Content-Length 呢，比如数据源还在不断的生成当中，不知道什么时候会结束。接下来还有第二种办法。</p>
</li>
<li>
<p>使用消息Header 字段，Transfer-Encoding:chunk</p>
<p>如果要一边产生数据，一边发给客户端，服务器就需要使用&quot;Transfer-Encoding: chunked&quot;这样的方式来代替Content-Length。</p>
<p>chunk编码将数据分成一块一块的发出。Chunked编码将使用若干个Chunk串连而成，由一个标明<strong>长度为0</strong>的chunk标示结束。每个Chunk分为头部和正文两部分，头部内容指定正文的字符总数（<strong>十六进制的数字</strong>）和数量单位（一般不写），正文部分就是指定长度的实际内容，两部分之间用**回车换行(CRLF)**隔开。在最后一个长度为0的Chunk中的内容是称为footer的内容，是一些附加的Header信息（通常可以直接忽略）。</p>
</li>
</ol>
<h4 id="抓包验证">抓包验证</h4>
<p>百闻不如一见，使用 WireShark 先抓为敬。<br>
chunk 编码方式抓包：<br>
Server 编码：</p>
<pre><code>func indexHandler(w http.ResponseWriter, r *http.Request) {
   //fmt.Print(r.Body.Read())
 fmt.Fprint(w, &quot;hello world&quot;)
}
func main() {
   http.HandleFunc(&quot;/report&quot;, indexHandler)
   http.ListenAndServe(&quot;:8000&quot;, nil)
}
</code></pre>
<p>Client 代码</p>
<pre><code>func main() {
   pr, rw := io.Pipe()
   go func(){
      for i := 0; i &lt; 100; i++ {
         rw.Write([]byte(fmt.Sprintf(&quot;line:%drn&quot;, i)))
      }
      rw.Close()
   }()
   http.Post(&quot;localhost:8000/&quot;,&quot;text/pain&quot;, pr)
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://chenat9.github.io/post-images/1606100756625.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://chenat9.github.io/post-images/1606100761885.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="4"><img src="https://chenat9.github.io/post-images/1606100766355.png" alt="" loading="lazy"></figure>
<p>从结果可以看出，HTTP 协议底层通过同一个 TCP 连接在发送数据。<br>
每一个TCP packet 的内容为我们写入的数据。</p>
<p>方式二：Content-Length<br>
Client编码</p>
<pre><code>func main() {
   count := 10
 line := []byte(&quot;linern&quot;)
   pr, rw := io.Pipe()
   go func() {
      for i := 0; i &lt; count; i++ {
         rw.Write(line)
         time.Sleep(500 * time.Millisecond)
      }
      rw.Close()
   }()
   // 构造request对象
 request, err := http.NewRequest(&quot;POST&quot;, &quot;http://localhost:8000/report&quot;, pr)
   if err != nil {
      log.Fatal(err)
   }
   // 提前计算出ContentLength
 request.ContentLength = int64(len(line) * count)
   // 发起请求
 http.DefaultClient.Do(request)
}
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://chenat9.github.io/post-images/1606100773785.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://chenat9.github.io/post-images/1606100778336.png" alt="" loading="lazy"></figure>
<p>当然底层依然是通过多次 tcp 包传输的。</p>
<h4 id="总结">总结</h4>
<p>为了解决不能将大数据一次性拼接到 Request 的 Body 中这个问题，采取了 HTTP 流式传输的方式，即边读进内存，边通过 HTTP 传输。</p>
<p>Keep-Alive 模式，避免了传输多个报文时，TCP 连接重复建立，为流式传输大量数据打好了基础。</p>
<p>Content-Length 和 Transfer-Encoding，两种方式为消息内容的长度判断提供了解决方案。</p>
<p>设置Content-Length的方式，由 Client 端持续将数据通过 HTTP 传输到 Server。chunk方式，Client 端将数据分片发包到 Server。</p>
<p>以上的方式都是通过建立一次 HTTP 传输完成的。</p>
]]></content>
    </entry>
</feed>